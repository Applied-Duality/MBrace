%
%	Section 1: Cloud Workflows
%

\section{Cloud Workflows}%
\label{sec:workflows}
%
Cloud workflows form the essential pillar of \mbrace{} design;
the programming model they introduce provides the ability to declare abstract
and modal expressions in a fluent, integrated manner, to be interpreted 
at some point in the future in a remote data center.

Cloud workflows are made possible thanks to a design pattern known as the \emph{monad}.
In short, monads are a language feature that allow the definition of language-integrated 
DSLs in a way where semantic peculiarities are abstracted away from the syntactic interface.
Monads have known success in languages such as Haskell, \csharp{} LINQ and Scala. 
In \fsharp, monads are manifested in a feature called 
Computation Expressions%
\footnote{See \samehref{http://msdn.microsoft.com/en-us/library/dd233182.aspx}}
that offer a range of overloadable language patterns, such as list comprehensions, 
queries, exception handling and even workflows traditionally associated with 
imperative programming, such as \texttt{for} loops and \texttt{while} loops.

A common instance of computation expressions provided with \fsharp{} is 
sequence comprehensions. Sequence comprehensions allow for language-integrated declaration 
of \dotnet{} enumerables. In the following example, an infinite odd number generator is 
defined:
\begin{lstlisting}
seq {
	let i = ref 0
	while true do
		yield 1 + 2 * i
		incr i
}
\end{lstlisting}
The \texttt{yield} keyword has semantics identical to the \csharp{} keyword of the same 
name. The \texttt{while} keyword operates in the anticipated manner but its implementation
is still particular to the sequence building context.

What makes computation expressions interesting is the fact that their instances
are not part of the \fsharp{} language per se. Rather, their implementations
reside in the library domain, hence any user could define computation expressions
of their own, giving for instance custom semantics to the \texttt{while} keyword 
without the need of any modification to the compiler\cite{fsharp-compexpr}.

\subsection{A Prelude: \fsharp{} Async Workflows}

In order to better understand cloud programming with \mbrace{}, 
one need think about asynchronous programming. 
Asynchrony in .NET and other frameworks has traditionally been 
associated with callback programming%
\footnote{See \samehref{http://msdn.microsoft.com/en-us/library/ms228963.aspx}}, 
a pattern that involves initializing asynchronous operations paired with the definition 
of a callback delegate to be invoked upon their completion.
This pattern however has been known to often result in complex and hard-to-read code.

\fsharp{} \emph{Asynchronous Workflows} enable the definition of asynchronous 
computations avoiding the need to explicitly program with callbacks\cite{fsharp-async}. 
With the help of \fsharp{} computation expressions, 
declaring a workflow is done in the illusion of sequential programming, 
when in actuality it is run asynchronously, 
suspending and resuming computation as required.
\begin{lstlisting}
let download (url : string) = async {
    let http = new System.Net.WebClient()
    let! html = http.AsyncDownloadString(Uri url)
    return html.Split('\n')
}
\end{lstlisting}
The above workflow asynchronously downloads the content of a web page 
and resumes to split it into lines once the download has been completed.

Async operations are composed with the special \texttt{let!} keyword, 
which can be thought of as syntactic sugar for the callback delegate passed
to the right-hand-side operation.
The \texttt{return} keyword denotes that the workflow should conclude, returning 
the value in the right hand side. A useful variant is the \texttt{return!} keyword, 
which concludes the workflow by calling another async computation:
\begin{lstlisting}
async {
    if String.IsNullOrWhiteSpace url then
        return Array.empty
    else
        return! download url
}
\end{lstlisting}
Observe how regular \fsharp{} language constructs, such as this \texttt{if} statement
are directly embeddable in \texttt{async} code blocks.

Asynchronous workflows are expressions of type \texttt{Async<\uq{}T>}
in which the generic parameter \texttt{\uq{}T} denotes their return type.
For instance, the above workflow will have type \texttt{Async<string []>}.

\fsharp{} async workflows can be utilized in scenaria where thread parallelism is required. 
The method
\centertt{Async.Parallel : Async<\uq{}T> seq -> Async<\uq{}T []>}
combines a given enumeration of workflows into a single asynchronous workflow 
that executes the given inputs in parallel, following a fork-join pattern:
\begin{lstlisting}
let workflow = async {
    let! results = 
        Async.Parallel 
			[ 
				download "http://www.m-brace.net" ;
				download "http://www.nessos.gr" 
			]
 
    return Seq.concat results |> Seq.length
}
\end{lstlisting}
This snippet will download the two pages asynchronously and will resume computation 
as soon as both operations have completed.

Async expressions have deferred execution semantics. They need to be passed to an
execution engine for evaluation to occur:
\begin{lstlisting} 
Async.Start workflow
\end{lstlisting}
Workflows are managed by a scheduler that transparently allocates pending jobs to the 
underlying \dotnet{} thread pool. A typical executing async expression will make jumps 
between multiple threads as it progresses.

The programming model introduced in \fsharp{} asynchronous workflows has been successful
enough that it has been adopted by other languages such as \csharp{} 5.0, Python and Haskell.

\subsection{The \TitularMbrace{} Programming Model}

The programming model of \mbrace{} follows very much in the style of \fsharp{} 
asynchronous workflows. \Mbrace{} introduces \emph{cloud workflows}
as a means of specifying distributed computation.
A cloud workflow has type \texttt{Cloud<\uq{}T>}, which represents a
deferred cloud computation that returns a result of type \texttt{\uq{}T} once executed.
Building on our previous declaration of the \texttt{download} async workflow, we could define
\begin{lstlisting}
[<Cloud>]
let lineCount() = 
	cloud {
    	let jobs : Cloud<string []> [] = 
        	Array.map (download >> Cloud.OfAsync) 
				[| "http://www.m-brace.net" ; "http://www.nessos.gr" |]

	    let! results = Cloud.Parallel jobs
    	return Array.concat results |> Array.length
	}
\end{lstlisting}
This is a direct adaptation of the \texttt{async} snippet presented above.
The main differences between this and \texttt{async} 
are the \texttt{cloud\{\}} keyword that delimits workflows
and the \texttt{Cloud.Parallel} combinator that actuates parallelism.
Semantically, \texttt{cloud} jobs are allocated to worker machines in the data center, 
just as \texttt{async} jobs are scheduled to threads in the thread pool. 
Like \texttt{async}, \texttt{cloud} workflows have deferred execution semantics 
and have to be sent to an \mbrace{} runtime for evaluation.
\begin{lstlisting}
// connect to a runtime
let runtime = MBrace.Connect "mbrace://grothendieck:2675"

// submit the computation
let cloudProc = runtime.CreateProcess <@ lineCount () @>

// wait for the result
cloudProc.AwaitResult()
\end{lstlisting}
%
%
Cloud workflows can be used to create user defined higher-order functions. 
For example, we could define a distributed variant of the classic filter combinator:
\begin{lstlisting}
[<Cloud>]
let filter (f : 'T -> bool) (xs : 'T []) =
    cloud {
		// a nested subexpression that performs
		// the checking on a single element
		let pick (x : 'T) =
			cloud {
				if f x then return Some x
				else
					return None
			}

        let! results = Cloud.Parallel <| Array.map pick xs
		return Array.choose id results
    }
\end{lstlisting}
%
%
Cloud workflows offer an extremely flexible programming model that can
be used to describe arbitrary computation patterns.
As proof of concept, we give a definition of the Ackermann%
\footnote{See \samehref{http://en.wikipedia.org/wiki/Ackermann\_function}} function:
\begin{lstlisting}
[<Cloud>]
let rec ackermann m n =
    cloud {
        match m, n with
        | 0, n -> return n + 1
        | m, 0 -> return! ackermann (m-1) 1
        | m, n ->
            let! rhs = ackermann m (n-1)
            return! ackermann (m-1) rhs
    }
\end{lstlisting}
%
\subsubsection*{Language Constructs}
%
Cloud workflows offer a multiplicity of overloaded language constructs,
including sequential operations such as \texttt{for} loops:
\begin{lstlisting}
cloud {
    for i in [| 1 .. 100 |] do
        do! Cloud.Logf "Entry #%d in the cloud process log" i
}
\end{lstlisting}
or \texttt{while} loops:
\begin{lstlisting}
cloud {
    while true do
        do! Cloud.Logf "Keep printing log entries forever!"
}
\end{lstlisting}
%
An important feature supported by cloud workflows is exception handling. 
Exceptions can be raised and caught in cloud workflows just as in any other piece 
of \fsharp{} or \dotnet{} code. 
\begin{lstlisting}
cloud {
    try
        let! x = cloud { return 1 / 0 }
        return x + y
    with :? System.DivideByZeroException as e ->
        // log and reraise
        do! Cloud.Logf "error: %O" e
        return raise e
}
\end{lstlisting}
This snippet will execute in the anticipated fashion, recording a message to the log
before completing the computation by re-raising the exception.
It is, however, the distributed nature of \mbrace{} that makes its exception 
handling mechanism particularly interesting. With cloud workflows, the symbolic execution
stack winds across multiple machines. Thus as exceptions are raised, they are passed
around multiple nodes before they are, if ever, returned to the user as a failed
computation result.

This is a good demonstration of what is one of the strengths of \mbrace.
Error handling in particular and computation state in general have a global and hierarchical
scope rather than one that is fragmented and localized.
This is achieved thanks to symbolic and distributed interpretation of what is known as
\emph{monadic trampolines}\cite{data-types-ala-carte, scala-trampolines}, 
also known as the ``monadic skeleton'' of a cloud workflow.


\subsubsection*{Example: Defining MapReduce}

MapReduce is a programming model that streamlines big scale distributed computation
on large data sets. Introduced by Google in 2003, it has known immense success in open
source implementations, such as Hadoop. MapReduce is a higher-order distributed algorithm
that takes two functions, \texttt{map} and \texttt{reduce} as its inputs. The \texttt{map}
function performs some computation on initial input, while the \texttt{reduce} function
takes two outputs from \texttt{map} and combines them into a single result. 
When passed to MapReduce, a distributed program is defined that performs the combined 
mappings and reductions on a given list of initial inputs.

Unlike other big data frameworks, where MapReduce comes as \emph{the} distribution primitive,
\mbrace{} makes it possible to define MapReduce-like workflows at the library level. 
A simplistic variant can be declared as follows:
\begin{lstlisting}
[<Cloud>]
let rec mapReduce (map: 'T -> Cloud<'R>) 
				    (reduce: 'R -> 'R -> Cloud<'R>) 
                    (identity: 'R) (input: 'T list) =
    cloud {
        match input with
        | [] -> return identity
        | [value] -> return! map value
        | _ ->
            let left, right = List.split input
 
            let! r1, r2 =
            	(mapReduce map reduce identity left)
            		<||>
	            (mapReduce map reduce identity right)
 
            return! reduce r1 r2
    }
\end{lstlisting}
This splits the list into halves and passes them 
recursively to the workflow using the parallel decomposition operator \texttt{<||>},
which is merely an abbreviation for \texttt{Cloud.Parallel} in the binary case.

A common example given when first describing MapReduce is the word count problem:
given a large collection of text files, compute their aggregate word frequencies.
This problem can be naturally distributed using the MapReduce pattern as follows:
the \texttt{map} function takes a file as input and returns its word frequency
count, while the \texttt{reduce} function takes two frequency counts and combines 
them into one.
The final MapReduce algorithm takes a large list of files and computes the total word
count in a distributed manner.

As an example, we give a simple implementation of wordcount in \mbrace{}.
First, the \texttt{map} workflow, which downloads the contents to a string,
splits it into tokens and performs the count:
\begin{lstlisting}
[<Cloud>]
let map (uri : string) : (string * int) [] =
    cloud {
        let! text = Cloud.OfAsync <| download uri

        return
            text
            |> Seq.collect (fun line -> line.Split([|' '|]))
            |> Seq.map (fun word -> word.Trim())
            |> Seq.filter (not << String.IsNullOrEmpty)
            |> Seq.groupBy id
            |> Seq.map (fun (word, occurences) -> word, Seq.length occurences)
            |> Seq.sortBy (fun (_,freq) -> -freq)
            |> Seq.toArray
    }
\end{lstlisting}
Second, the \texttt{reduce} worfklow, which combines two given frequences:
\begin{lstlisting}
[<Cloud>]
let reduce (freq1 : (string * int) []) (freq2 : (string * int) []) =
    cloud {
        return
            Seq.append freq1 freq2
            |> Seq.groupBy fst
            |> Seq.map (fun (word, freqs) -> word, Seq.sumBy snd freqs)
            |> Seq.sortBy (fun (_,freq) -> -freq)
            |> Seq.toArray
    }
\end{lstlisting}
Finally, everything is combined with \texttt{mapReduce} and sent to a runtime:
\begin{lstlisting}
// create an input set
let inputs =
    let resource = "http://www.textfiles.com/etext/AUTHORS/SHAKESPEARE/"
    let works =
        [|
            "shakespeare-hamlet-25.txt"
            "shakespeare-othello-47.txt"
            "shakespeare-tragedy-58.txt"
        |]
    works |> Array.map (fun w -> System.IO.Path.Combine(resource, w))
    
// put everything together and execute in runtime
runtime.CreateProcess <@ mapReduce mapF reduceF [||] inputs @>
\end{lstlisting}

\subsection{Distribution Primitives}

In this section we offer a detailed description of all distribution related
primitives used in \mbrace{}.

\subsubsection*{Parallelism}

The \texttt{Cloud.Parallel} combinator is used to execute cloud workflows in a parallel, 
fork-join pattern. Its type signature is
\centertt{Cloud.Parallel : Cloud<\uq{}T> seq -> Cloud<\uq{}T []>}
This takes an array of cloud computations and returns a workflow that executes them
in parallel, returning an array of all results.
The parent computation will resume as soon as all of the child computations have completed.
\begin{lstlisting}
cloud {
    let f x = cloud { return x * x }
    let jobs = [| for i in 1 .. 100 -> f i |]   
    let! results = Cloud.Parallel jobs
    return Array.sum results
}
\end{lstlisting}
%
Exception handling has similar semantics to \texttt{Async.Parallel}.
Unhandled exceptions thrown by any of the child processes will
bubble up at the combinator callsite and all pending child computations
will be cancelled as a consequence.

\subsubsection*{Nondeterministic Computation}
%
In addition to \texttt{Cloud.Parallel}, \mbrace{} offers the distribution primitive
\centertt{Cloud.Choice : Cloud<\uq{}T option> seq -> Cloud<\uq{}T option> }
that combines a collection of nondeterministic computations into one.
A computation that returns optionals is nondeterministic in the sense that
it may either succeed by returning \texttt{Some} value of type \texttt{\uq{}T} or
fail by returning \texttt{None}.
What the \texttt{Choice} combinator does is execute its inputs in parallel,
returning a result as soon as the first child completes successfully 
(with \texttt{Some} result) and actively cancels all pending child computations.
The combinator returns \texttt{None} if all child computations have completed
without success (each returning \texttt{None}).
For those familiar with the \fsharp{} library, this is essentially a distributed
version of \texttt{Array.tryPick}.

The \texttt{Choice} combinator is particularly suited for distributing decision problems,
such as \texttt{SAT} solvers or large number factorization.
As an example, we give the implementation of a distributed existential combinator:
\begin{lstlisting}
[<Cloud>]
let exists (f : 'a -> Cloud<bool>) (inputs : 'a []) : Cloud<bool> =
    cloud {
        let pick (x : 'a) =
            cloud {
                let! result = f x
                return
                    if result then Some x
                    else None
            }

        let! result = Cloud.Choice <| Array.map pick inputs
        return result.IsSome 
    }
\end{lstlisting}

\subsubsection*{Embedding Asynchronous Workflows}

As has been demonstrated in previous examples, asynchronous workflows can be
embedded in cloud expressions using the
\centertt{Cloud.OfAsync : Async<\uq{}T> -> Cloud<\uq{}T>}
combinator. It should be noted that the combinator does \emph{not} alter the
original \texttt{async} semantics in any way. For instance, wrapping an
\texttt{Async.Parallel} expression with \texttt{Cloud.OfAsync} will not introduce
any form of distribution as witnessed in \texttt{Cloud.Parallel}. Rather,
it will execute as before, initiating thread parallelism in its current
local context.

The \texttt{Cloud.OfAsync} primitive is particularly useful for utilizing
already existing \texttt{async} libraries in cloud workflows. For instance,
one could define the extension method
\begin{lstlisting}
type Cloud with
    [<Cloud>]
    static member Sleep interval = 
    	Cloud.OfAsync (Async.Sleep interval)
\end{lstlisting}
which can then be used in the expected fashion
\begin{lstlisting}
cloud {
    do! Cloud.Sleep 10000
    return 42
}
\end{lstlisting}

\subsubsection*{Local Execution}
\label{localCombinator}

There are cases where constraining the execution of a cloud workflow in the context of a
single worker node might be extremely useful. This can be performed using the
\centertt{Cloud.ToLocal : Cloud<\uq{}T> -> Cloud<\uq{}T>}
primitive, or its \texttt{local} abbreviation. The combinator transforms any given
cloud workflow into an equivalent expression that executes in a strictly local context,
forcing concurrency semantics largely similar to those of \texttt{async} (see also section \ref{localSemantics}).

The \texttt{local} primitive is particularly handy when it comes to effectively managing 
computation granularity. As an example, we give an enhanced version of the previous 
\texttt{mapReduce} implementation. The original \texttt{mapReduce} implementation would 
fork itself on successive binary splits of the input data, until exhaustion thereof.
This works in principle, but it does put considerable strain on the scheduling mechanism of
\mbrace, particularly when the input length is considerably larger than the cluster's
worker count.

In this version, a more elaborate distribution strategy shall be followed.
Again, inputs are to be forked successively, but at a depth no larger than the logarithm
of the cluster size. This ensures that each worker node will receive roughly one group
of inputs during the computation's lifetime. Subsequently, each worker node will continue
executing the same MapReduce workflow \emph{locally}, this time adhering to a maximum 
depth related to the current machine's processor count. Once all CPU cores have been
exhausted, each block of inputs is processed sequentially in a singly-threaded fold pattern.
\begin{lstlisting}
// type used internally to distinguish between operation modes
type DistributionContext =
    | Distributed
    | LocalParallel
    | Sequential

[<Cloud>]
let mapReduce   (mapF : 'T -> Cloud<'R>)
                (reduceF : 'R -> 'R -> Cloud<'R>)
                (identity : 'R) (input : 'T list) : Cloud<'R> =

    let computeDepth (workers : int) = 
        let log2 n = log n / log 2.0
        workers |> float |> log2 |> round |> int
 
    let rec traverse context depth input =
        cloud {
            match context, depth, input with
            | _, _, [] -> return identity
            | _, _, [x] -> return! mapF x
            // exhausted depth in distributed context, switch to local parallelism
            | Distributed, 0, _ ->
            	let depth = computeDepth Environment.ProcessorCount
                return! local <| traverse LocalParallel depth input
            // exhausted depth in local parallelism context, switch to sequential
            | LocalParallel, 0,_ -> return! traverse Sequential depth input
            // binary parallel split
            | (Distributed | LocalParallel), _, _ ->
                let left, right = List.split input

                let! leftR, rightR = 
                    (traverse context (depth - 1) left) 
                        <||> 
                    (traverse context (depth - 1) right)

                return! reduceF leftR rightR
            // sequential computation context
            | Sequential, _, _ ->
                let rec traverseSequential current input =
                    cloud {
                        match input with
                        | [] -> return current
                        | t :: rest ->
                            let! s = mapF t
                            let! current' = reduceF current s
                            return! traverseSequential current' rest
                    }

                return! traverseSequential identity input
        }

    cloud {
    	// probe runtime for number of worker nodes
        let! workers = Cloud.GetWorkerCount()
        return! traverse Distributed (computeDepth workers) input
    }
\end{lstlisting}

\subsection{Distributing Data}

Cloud workflows offer a programming model for distributed computation.
But what happens when it comes to big data?
While the distributable execution environments of \mbrace{} do offer a
limited form of data distribution, their scope is inherently local
and almost certainly do not scale to the demands of modern big data applications.
\Mbrace{} offers a plethora of mechanisms for managing data in a more global and massive
scale. These provide an essential decoupling between distributed computation and
distributed data.

\subsubsection*{Cloud Refs}

The \mbrace{} programming model offers access to persistable and distributed data entities
known as \texttt{cloud refs}. Cloud refs very much resemble \emph{references} found in the 
\texttt{ML} family of languages but are “monadic” in nature. In other words, their declaration
entails a scheduling decision by the runtime. The following workflow stores the downloaded
content of a web page
and returns a cloud ref to it:
\begin{lstlisting}
[<Cloud>]
let getRef () =
    cloud {
        let! lines = Cloud.OfAsync <| download "http://www.m-brace.net"
        let! ref = CloudRef.New lines
        return ref
    }
\end{lstlisting}
When run, this will return a unique identifier that can be subsequently 
dereferenced either in the context of the client or in a future cloud computation:
\begin{lstlisting}
// receive a cloud ref
let r : ICloudRef<string []> = runtime.Run <@ getRef () @>

// dereference locally
let data : string [] = r.Value
\end{lstlisting}

The values of cloud refs are recorded in a \emph{storage provider} that
connects to the \mbrace{} runtime. \Mbrace{} transparently manages storage,
while it also aggressively caches local copies to select worker nodes.
Scheduling decisions are taken with respect to caching affinity, 
resulting in minimized copying of data.

Cloud refs are \emph{immutable} by design, they can either be initialized or dereferenced.
Immutability eliminates synchronization issues, resulting in efficient caching 
and enhanced access speeds. In the sections ahead we will describe
\hyperref[mutableCloudRef]{\texttt{MutableCloudRef}}, a mutable variant of the cloud ref.

An interesting aspect of cloud refs is the ability to define large, distributed
data structures. For example, one could define a distributed binary tree like so:
\begin{lstlisting}
type CloudTree<'T> = 
	| Empty
    | Leaf of 'T
	| Branch of TreeRef<'T> * TreeRef<'T>

and TreeRef<'T> = ICloudRef<CloudTree<'T>>
\end{lstlisting}
The cloud tree gives rise to a number of naturally distributable operations like
\begin{lstlisting}
let rec map (f : 'T -> 'S) (ttree : TreeRef<'T>) = cloud {
    match ttree.Value with
    | Empty -> return! CloudRef.New Empty
    | Leaf t -> return! CloudRef.New <| Leaf (f t)
    | Branch(l,r) ->
        let! l',r' = map f l <||> map f r
        return! CloudRef.New <| Branch(l', r')
}
\end{lstlisting}
and
\begin{lstlisting}
let rec reduce (id : 'R) (reduceF : 'R -> 'R -> 'R) (rtree : TreeRef<'R>) = cloud {
    match rtree.Value with
    | Empty -> return id
    | Leaf r -> return r
    | Branch(l,r) ->
        let! r,r' = reduce id reduceF l <||> reduce id reduceF r
        return reduceF r r'
}
\end{lstlisting}
Cloud trees can be materialized materialized from an original data set like so:
\begin{lstlisting}
let rec initTree (values : 'T list) : TreeRef<'T> =
    cloud {
        match values with
        | [] -> return! CloudRef.New Empty
        | [t] -> return! CloudRef.New <| Leaf t
        | _ ->
            let left, right = List.split values
            let! l = initTree left 
            let! r = initTree right
            return! CloudRef.New <| Branch(l,r)
   }
\end{lstlisting}
We can now use the above definitions to perform MapReduce-like queries on distributed data.
Recall the Shakespeare wordcount example:
\begin{lstlisting}
// create a cloud tree containing the works of Shakespeare
let wtree : TreeRef<string> = runtime.Run <@ initTree works @>
// use map to calculate individual frequences
let ftree : TreeRef<(string * int) []> = runtime.Run <@ map mapF wtree @>
// use reduce to calculate the aggregate frequency
let freq : (string * int) [] = runtime.Run <@ reduce [||] reduceF ftree @>
\end{lstlisting}
The above functions enable distributed MapReduce workflows that are 
driven by the structural properties of the cloud tree.
The use of cloud refs accounts for data parallelism in a way not achievable
by the previous MapReduce examples.

It is possible to define a MapReduce workflow that combines both control
over runtime granularity \emph{and} effective data parallelism through sharding.
Examples of this can be found in the MapReduce implementations of the \texttt{MBrace.Lib}
assembly.

\subsubsection*{Mutable Cloud Refs}
\label{mutableCloudRef}

The \texttt{MutableCloudRef} primitive is, similarly to the \texttt{CloudRef},
a reference to data saved in the underlying storage provider. However,
\begin{itemize}
\item \texttt{MutableCloudRef}s are \emph{mutable}. The value of a mutable cloud ref
can be updated and, as a result, its values are never cached. Mutable cloud refs can
be updated \emph{conditionally} using the \texttt{MutableCloudRef.Set} methods or 
\emph{forcibly} using the \texttt{MutableCloudRef.Force} method.
\item \texttt{MutableCloudRef}s can be \emph{deallocated} manually. This can be done
using the \texttt{MutableCloudRef.Free} method.
\end{itemize}
The \texttt{MutableCloudRef} is a powerful primitive that can be used to create 
runtime-wide synchronization mechanisms like locks, semaphores, etc.

The following demonstrates simple use of the mutable cloud ref:
\begin{lstlisting}
[<Cloud>]
let example1 () = cloud {
    let! mr = MutableCloudRef.New(0)
 
    let! _ = 
    	MutableCloudRef.Force(mr,1)
    		<||> 
    	MutableCloudRef.Force(mr,2)
 
    return! MutableCloudRef.Read(mr)
}
\end{lstlisting}
The snippet will return a result of either 1 or 2, depending on which update operation
was run last.

Finally, the following snippet implements an optimistic incrementing function
acting on a mutable cloud ref:
\begin{lstlisting}
[<Cloud>]
let increment (counter : IMutableCloudRef<int>) = cloud {
    let flag = ref false
    while not !flag do
        let! v = MutableCloudRef.Read counter
        let! ok = MutableCloudRef.Set(counter, v + 1)
        flag := ok
}
\end{lstlisting}
The same effect can be achieved using the included 
\texttt{MutableCloudRef.SpinSet} method
\begin{lstlisting}
[<Cloud>]
let increment' (counter : IMutableCloudRef<int>) = cloud {
    do! MutableCloudRef.SpinSet(counter, fun x -> x + 1)
}
\end{lstlisting}

\subsubsection*{Cloud Sequences}

While cloud refs are useful for storing relatively small chunks of data,
they might not scale well when it comes to large collections of objects.
Evaluating a cloud ref that points to a big array may place
unnecessary memory strain on the runtime. For that reason,
\mbrace{} offers the \texttt{CloudSeq} primitive, 
a construct similar to the \texttt{CloudRef} that offers access to
a \emph{collection} of values with on-demand fetching semantics.
The \texttt{CloudSeq} implements the \dotnet{} \texttt{IEnumerable} interface 
and is immutable, just like the \texttt{CloudRef}.

In the following snippet, we present an example of how cloud sequences can be
used on the previously defined \texttt{download} workflow:
\begin{lstlisting}
[<Cloud>]
let downloadCS (url : string) =
    cloud {
        let! lines = Cloud.OfAsync <| download url
        return! CloudSeq.New lines
    }
    
let cs = runtime.Run <@ downloadCS "http://www.m-brace.net/" @>
\end{lstlisting}
The returned cloud file can now be evaluated on demand with the usual \fsharp{} 
sequence combinators
\begin{lstlisting}
cs |> Seq.take 10 |> Seq.toArray
\end{lstlisting}

\subsubsection*{Cloud Files}

The final construct in the class of storage primitives offered in \mbrace{}
is the \texttt{CloudFile}. As is evident by its name, the \texttt{CloudFile}
is a reference to a file saved in the global store. In other words, it is an
interface for storing or accessing binary blobs in the runtime.
\begin{lstlisting}
[<Cloud>]
let saveToCloudFile (url : string) : Cloud<ICloudFile> =
    cloud {
        let! lines = Cloud.OfAsync <| download url
        return! CloudFile.WriteAllLines lines
    }
    
let cloudFile = runtime.Run <@ saveToCloudFile "http://www.m-brace.net/" @>

// read cloud file locally
cloudFile.AllLines() |> Seq.take 5 |> String.concat "\n"
\end{lstlisting}

\subsubsection*{Disposing Distributed Resources}

All constructs mentioned above manifest themselves by allocating space in the
storage back end of the runtime. They thus occupy resources associated with
the global distribution context and which are not garbage collectable by
individual workers in the cluster. Such ``globally scoped'' items give rise
to the need for distributed deallocation facilities.

The \mbrace{} programming model offers a mechanism for performing such deallocations
as well as a syntactic facility for scoped resource management. 
All of the aforementioned data constructs implement the \texttt{ICloudDisposable}
interface, which has the signature
\begin{lstlisting}
type ICloudDisposable =
  interface
    inherit ISerializable
    abstract member Dispose : unit -> Async<unit>
  end
\end{lstlisting}
This can be thought of as a distributed version of the \texttt{IDisposable}
interface available in \dotnet. Similarities do not stop there; just as
\dotnet{} languages offer the \texttt{using} keyword%
\footnote{\texttt{using} keyword in \csharp, see 
\samehref{http://msdn.microsoft.com/en-us/library/yh598w02.aspx}} 
that allows for scoped introduction of disposable resources, 
\mbrace{} workflows come with the \texttt{use} and \texttt{use!} keywords that 
apply to \texttt{ICloudDisposable} entities. For instance,
\begin{lstlisting}
cloud {
	try
		use! cref = CloudRef.New ``huge array``
		let success = ref false
	
		while not success.Value do
			let! s = ``distributed computation`` cref
			success := s

		// scope of cloud ref ends here, 
		// workflow implicitly disposes it
	with e ->
		do! Cloud.Logf "error: %A" e
		
	// at this point, the cloud ref will have 
	// been disposed of regardless of the outcome
	return ()
}
\end{lstlisting}
Initializing a cloud ref with the \texttt{use} keyword provides the assurance 
that it will be deallocated from the global store as soon as the workflow has 
exited its scope. In conformance to standard \texttt{using} semantics,
this will occur regardless of whether the computation has completed normally
or exited with an exception.

\subsubsection*{\TitularMbrace{} Storage Providers}

The \mbrace{} runtime stores and manages distributed data entities using a
pluggable storage provider facility. Runtime administrators can specify one
of the available storage providers, such as FileSystem, SQL or Azure blob storage
providers; or they could provide custom storage provider implementations of their own.
Custom providers can be realized by implementing the \texttt{IStore} and
\texttt{IStoreFactory} interfaces.

\subsection{Runtime \& Debugging Primitives}

In this section we present an assortment of primitives offered by \mbrace{}
that enable the collection of runtime-specific information as well as tools
that enhance the debugging process of distributed computations.

\subsubsection*{Cloud.GetWorkerCount}

The primitive
\centertt{Cloud.GetWorkerCount : unit -> Cloud<int>} 
can be used to retrieve the number of worker nodes currently available in the 
runtime cluster. It should be noted that the returned result differs when
interpreted under \texttt{local} semantics:
\begin{lstlisting}
cloud {
	// gets the number of worker nodes in the cluster
	let! workers = Cloud.GetWorkerCount ()
	// gets the number of logical cores in the currently executing machine
	let! cores = Cloud.ToLocal <| Cloud.GetWorkerCount () in ()
}
\end{lstlisting}

\subsubsection*{Cloud.GetProcessId}

The \mbrace{} runtime is capable of hosting multiple distributed processes concurrently.
This happens much in the sense of a distributed OS, in which every \emph{cloud process}
is assigned a \emph{process id} of its own. The id of a currently running process can
be retrieved within its own workflow using the
\centertt{Cloud.GetProcessId : unit -> Cloud<ProcessId>}
primitive.

\subsubsection*{Cloud.GetTaskId}

The execution of a cloud process in \mbrace{} is manifested in the distribution of
a multitude of tasks to the worker pool provided by the runtime, much in the
sense of tasks being sent to the CLR thread pool by \texttt{async}.
The \texttt{Cloud.GetTaskId} primitive returns the \emph{task id} of the current
execution context and can be thought of as analogous to the CLR thread id.
\begin{lstlisting}
cloud {
	let! parentId = Cloud.GetTaskId ()
	let! childId, childId' = Cloud.GetTaskId () <||> Cloud.GetTaskId ()
	
	// should return distinct task id's
	return (parentId, childId, childId')
}
\end{lstlisting}

\subsubsection*{Cloud.Log}

Each cloud process comes with a cluster-wide log that can be used to record
user-generated messages throughout its lifetime. Writing to the
the \emph{process log} can be done using the
\centertt{Cloud.Log : string -> Cloud<unit>}
primitive. Similar to the \texttt{printf} function available in \fsharp{} 
is the \texttt{Cloud.Logf} combinator.
\begin{lstlisting}
[<Cloud>]
let verbose () =
    cloud {
        for i in [| 1 .. 4 |] do
            do! Cloud.Logf "iteration %d: %A" i System.DateTime.Now
            do! Cloud.OfAsync <| Async.Sleep 100
    }

let proc = runtime.CreateProcess <@ verbose () @>

// dump logs to client buffer
runtime.ShowUserLogs proc.ProcessId
\end{lstlisting}

\subsubsection*{Cloud.Trace}
The \texttt{Cloud.Log} combinator can also be used for ``printf debugging''. 
In larger programs however, this can become a tedious undertaking, 
so the \texttt{Cloud.Trace} combinator can be used instead. 
The primitive has type signature
\centertt{Cloud.Trace : computation:Cloud<\uq{}T> -> Cloud<\uq{}T>}
It essentially augments the given cloud workflow with the effect of printed trace information
(local variables, symbolic stack trace, etc)
in the user logs. Trace information can be fetched in the same way as user logs. 
The following example offers a demonstration:
\begin{lstlisting}
[<Cloud>]
let trace () =
    cloud {
        let a, b = 4, 5
        let! (c,d) = cloud { return a + 1 } <||> cloud { return b + 1 }
        return c * d
    }
    
let proc = runtime.CreateProcess <@ trace () |> Cloud.Trace @>

// retrieve trace info
rt.ShowUserLogs proc.ProcessId
\end{lstlisting}
In some cases it may be useful to restrict tracing to specific portions of our code. 
This can be done by affixing the \texttt{NoTraceInfo} attribute on top of workflow\
definitions.
\begin{lstlisting}
[<Cloud; NoTraceInfo>]
let add a b = cloud { return a + b }
 
[<Cloud>]
let sub a b = cloud { return a - b }
 
[<Cloud>]
let example () =
    cloud {
        let! x = add 22 22
        return! sub x 2
    }
    
let proc = runtime.CreateProcess <@ example () |> Cloud.Trace @>

// no trace info for addition workflow
rt.ShowUserLogs proc.ProcessId
\end{lstlisting}

\subsection{Syntax \& Semantics}

This section offers a detailed view on the syntax and discusses certain semantic 
intricacies related to distributed workflows.

\subsubsection*{Syntactic Forms}

In the following BNF we denote the valid syntactic forms for composing cloud workflows. 
\fsharp{} expressions are denoted by \texttt{expr} and cloud expressions are denoted by 
\texttt{cexpr}.
\begin{lstlisting}
expr := cloud { cexpr }             // syntactic formation of cloud workflows
 
cexpr :=
| do! expr							// execute Cloud<unit>
| let! pat = expr in cexpr          // execute Cloud<'T> & bind 
| let pat = expr in cexpr           // let binding in a cloud workflow
| use! res = expr in cexpr          // monadic binding on ICloudDisposable object
| use res = expr in cexpr           // binding on ICloudDisposable object
| return! expr                      // tailcall position in cloud workflows
| return expr                       // return result 
| cexpr; cexpr                      // sequential composition, first cexpr must be of Cloud<unit> 
| if expr then cexpr else cexpr     // conditional 
| match expr with pat -> cexpr      // match expression
| while expr do cexpr               // while loop on synchronous guard
| for pat in expr do cexpr          // for loop on synchronous array
| try cexpr with pat -> cexpr       // cloud exception handling
| try cexpr finally expr            // cloud compensation
| expr                              // execute expression for side effects
\end{lstlisting}

\subsubsection*{Semantic Similarities to Async}

Most syntactic forms found in cloud workflows largely follow the semantic interpretation
given in \fsharp{} Async workflows\cite{fsharp-async}. One interesting example of semantic
similarity is the following: In Async workflows, concurrency is actualized in a 
\texttt{let!} binding (or any other \texttt{!} operation) of specific concurrency-based 
\texttt{async} functions. \texttt{Async.Parallel} is a good example of a function that uses 
concurrency for enabling parallelism.

In the following example we can observe that \texttt{Async.Parallel} introduces concurrency 
in the form of thread hopping:
\begin{lstlisting}
open System.Threading
 
let worker() = 
    async { 
        do Thread.Sleep 10 // simulate work
        return Thread.CurrentThread.ManagedThreadId 
    }
 
async {
    let! t1 = worker ()
    let! t2 = worker ()
    let! [|t3; t4|] = Async.Parallel [| worker () ; worker () |]
    let! t5 = worker ()
    return (t1, t2, t3, t4, t5)
} |> Async.RunSynchronously
\end{lstlisting}
The above example clearly demonstrates that \texttt{let!} composition does not
initiate thread hopping per se, but rather, this depends on the type of workflow
invoked on the right-hand-side of the binding. Of course, this behaviour is not
unique to \texttt{Async.Parallel}, but can be initiated with a multitude of
primitive \texttt{async} operations:
\begin{lstlisting}
async {
    let! t1 = worker ()
    let! t2 = worker ()
    // call non-blocking sleep workflow
    do! Async.Sleep 10
    // continutation should reschedule in a different thread
    let! t3 = worker ()
    return (t1,t2,t3)
} |> Async.RunSynchronously
\end{lstlisting}
In cloud workflows we have an analogous situation. Async workflows are scheduled in 
a thread pool and we can observe the effect with a thread id.
In an analogous manner, cloud workflows are scheduled in a worker pool of nodes 
and the same effect can be observed by way of task ids.
\begin{lstlisting}
cloud {
    let! t1 = Cloud.GetTaskId()
    let! t2 = Cloud.GetTaskId()
    let! t3 = Cloud.GetTaskId()
    return (t1, t2, t3)
} 
\end{lstlisting}
In the preceding example the task id's are identical, but once parallelism
is introduced, the result is changed:
\begin{lstlisting}
cloud {
    let! t1 = Cloud.GetTaskId()
    // Parallel fork-join
    let! t2, t3 = Cloud.GetTaskId() <||> Cloud.GetTaskId()
    let! t4 = Cloud.GetTaskId()
    return (t1, t2, t3, t4)
} 
\end{lstlisting}
The different task id's indicate that each of the operations have been executed
in different worker nodes.

\label{peculiarities}
\subsubsection*{Semantic Peculiarities}

Due to the inherently distributed nature of execution, cloud workflows demonstrate
certain divergences from standard Async semantics.
\begin{lstlisting}
let race () =
    async {
        let r = ref 0
        let! _ = Async.Parallel [| for i in 1 .. 1000 -> async { incr r } |]
        return !r
    }
\end{lstlisting}
The example above is the prototypical race condition demonstrated in Async workflows.
However, once we try to translate this into \mbrace, we get a different story
\begin{lstlisting}
[<Cloud>]
let race' () =
    cloud {
        let r = ref 0
        let! _ = Cloud.Parallel [| for i in 1 .. 1000 -> cloud { incr r } |]
        return !r
    }

runtime.Run <@ race' () @>
\end{lstlisting}
The above computation will always yield 0. This happens because of the way distribution
occurs: each worker node will receive a serialized \emph{copy} of the original environment;
since that is merely a collection of marshalled \dotnet{} objects passed into arbitrary
native methods, there is no obvious way in which cross-runtime synchronization can occur.
Copies of the environment that are passed to child workflows are discarded as soon as the
relevant computation has completed. Pending parent computations are only to be updated with
the \emph{results} returned by child computations, or forwarded an exception.

A further example highlights this copying behaviour
\begin{lstlisting}
cloud {
    let x = [1..10]
    let! y,_ = cloud { return x } <||> cloud { return () }
    return obj.ReferenceEquals(x, y)
}
\end{lstlisting}
in which one can easily deduce that the returned result is going to be \texttt{false}.

The obvious question at this point is how one could enforce cross-runtime
synchronization of values. There are two answers to this: the first one would be
to adopt a purely functional style of programming, eschewing control flow using mutable
objects. The second solution (if the former is deemed to be too impractical) would be
to use the purpose-built \hyperref[mutableCloudRef]{\texttt{MutableCloudRef} primitive} that 
provides all required synchronization guarantees.

\label{localSemantics}
Special mention needs to be made of the \hyperref[localCombinator]{\texttt{local} combinator},
which essentially reinterprets cloud workflows in a localized context,
substantially altering the execution semantics. While most of it is retrofitted
to match the behaviour of \texttt{async}, certain aspects remain different.
In particular, the copying behaviour observed in the distributed setting is emulated here
in order to maintain a degree of consistency. This can be demonstrated in the following
snippet:
\begin{lstlisting}
cloud {
    let r = ref 0
    let! _ = local <| 
    	Cloud.Parallel [| for i in 1 .. 1000 -> cloud { incr r } |]

    return !r
}
\end{lstlisting}
Just as before, this workflow will yield 0, even though its execution would never
escape the context of a single worker node. This should not be confused with the
behaviour of \texttt{Cloud.OfAsync} however, which preserves the original \texttt{async}
semantics:
\begin{lstlisting}
cloud {
	// still a race condition!
	return! Cloud.OfAsync <| race ()
}
\end{lstlisting}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "mbrace"
%%% End: 
