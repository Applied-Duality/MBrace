\section{Introduction}%
%
As cloud computing and big data gain prominence in today's economic landscape,
the challenge of effectively articulating complex algorithms in distributed environments
becomes ever more important.
%
In this article we describe \mbrace; a novel programming model/framework for performing
large scale computation in the cloud. Based on the \dotnet{} software stack, it utilizes
the power of the \fsharp{} programmming language.
\Mbrace{} introduces a declarative style for specifying and composing parallelism patterns,
in what is known as \emph{cloud workflows} or the \emph{cloud monad}.
\Mbrace{} is also a distributed execution runtime that handles orchestration of cloud 
workflows in the data centre.
%
\subsection{Cloud Programming Today}
%
We live in the era of big data and cloud computing. Massive volumes of unstructured 
data are constantly collected and stored in huge data centres around the world. 
Data scientists and computer engineers face the formidable task of managing and 
analysing huge volumes of data in a massively distributed setting where thousands of 
machines spend  hours or even days executing sophisticated algorithms.
Programming large-scale distributed systems is a notoriously difficult task
that requires expert programmers orchestrating concurrent processes in a setting
where hardware/\mbox{}software failures are incessantly commonplace.
The key to success in such scenaria is selecting a distribution framework that provides the
correct programming abstractions and automates handling of scalability and fault tolerance.
Several abstractions have been proposed and many interesting implementations are
currently under development.

One of the most popular distributed programming paradigms is the
MapReduce model. Introduced by Google\cite{map-reduce} in 2003, MapReduce is inspired by the \texttt{map}
and \texttt{reduce} functions commonly found in functional programming. MapReduce is
particularly suitable for application deployment in which vast amounts of unstructured
data can be processed. The MapReduce model has been implemented in multiple frameworks,
the most successful of which is the \emph{Hadoop} software framework.
Based on Java, the MapReduce engine of Hadoop handles in-parallel 
distribution and execution of tasks on large clusters of nodes in a reliable, 
fault-tolerant manner.  One of the major criticisms of Hadoop over the years is the 
lack for soft-realtime and streaming computations, although some of these concerns are 
going to be addressed by the \texttt{YARN} project%
\footnote{Apache Hadoop \texttt{YARN},
see \samehref{http://hortonworks.com/blog/apache-hadoop-yarn-background-and-an-overview/}.}. 

Another interesting and much more expressive approach comes from the Haskell community and 
is based on the idea that strong types and monads can offer a composable model for
programming with \emph{effects}. CloudHaskell\cite{cloud-haskell} and HdpH\cite{HdpH} are 
two new projects based on monads for composing distributed computations but with slightly
different approaches:
%
\begin{itemize}
\item CloudHaskell is based on a \emph{Process monad} which provides a message passing 
communication model, inspired by Erlang, and a novel technique for serializing closures. 
The Process monad is used as a shallow DSL embedding for the channel oriented 
communication layer and is indented as a low-level layer for building larger 
abstractions.

\item HdpH is influenced by the \texttt{Par} monad\cite{par-monad} and the work on closure
serialisation found in CloudHaskell. It provides a high-level semi-explicit parallelism via 
the use of a distributed generalization of the \texttt{Par} monad. One interesting design
approach is the use of global references for communication purposes and data sharing.
\end{itemize}

A common trait that many distributed frameworks share is the adoption of patterns and
principles most commonly associated with functional programming languages. Indeed, 
it has been argued that functional programming may offer a natural setting for 
effectively describing distributed computation.

\subsection{The \TitularMbrace{} framework}

\Mbrace{} is a distributed programming model and framework powered by the \dotnet{}
software stack. Based on the \fsharp{} programming language, it offers an expressive
and integrated way of developing, deploying and debugging large-scale computations
running in the cloud. \Mbrace{} is capable of distributing arbitrary code and
offers native access to the rich collection of tested libraries offered with the
underlying \dotnet{} framework. \Mbrace{} draws heavy inspiration from the Haskell 
community, especially from the work on concurrency/parallelism and shares many similar
ideas with the HdpH project. Its programming model is founded on the premise that monads 
in a recursive higher-order language offer a rich substrate for expressing many
different kinds of algorithmic patterns such as MapReduce, streaming\cite{ShmStreaming},
iterative\cite{HaLoop} or incremental\cite{IncMR} algorithms. Unlike Hadoop, such 
patterns can be defined at the user level as libraries, without the need to change any
underlying runtime infrastructure.

\subsubsection*{The \TitularMbrace{} Programming Model}

\Mbrace{} introduces a new programming model for the cloud, one that offers a 
\emph{compositional} and \emph{declarative} approach to describing distributed 
computations. This is achieved with the help of \fsharp{} \emph{computation expressions} 
that enable fluent, language-integrated \emph{cloud workflows}, in a model also known
as a \emph{cloud monad}. Concurrency patterns and overall execution semantics are specified 
with the help of primitive combinators that operate on such cloud workflows.
%
\begin{lstlisting}
cloud {
	let job1() = cloud { return 1 }
	let job2() = cloud { return 2 }
	let! [| result1 ; result2 |] = Cloud.Parallel [| job1() ; job2() |]	
	return result1 + result2
}
\end{lstlisting}
The above \fsharp{} snippet defines two small cloud workflows, \texttt{job1} and
\texttt{job2} which are then passed to the \texttt{Cloud.Parallel}
combinator. This declares that the jobs are to be executed in a parallel
fork/join pattern. The workflow further specifies that once both jobs have
completed, the parent workflow will resume its computation and return the final
result.
%

\subsubsection*{The \TitularMbrace{} Distributed Runtime}

Cloud workflows denote deferred computation; their execution can only be performed within
the context of a distributed environment, such as the runtime that the \mbrace{}
framework provides. The \emph{\mbrace{} runtime} is a scalable cluster infrastructure that
enables distributed abstract machine execution for cloud workflows.
The runtime interprets the monadic structure of workflows using a scheduler/worker hierarchy, 
transparently allocating computational resources to pending cloud jobs.

For instance, in the cloud workflow declared above, the forked jobs will be
scheduled in two separate worker machines transparently designated by the
runtime. Once both have completed, computation will resume in another allocated
worker, potentially not the same as the one where the forking was originally
initiated. What this means is that cloud workflows are executed in a
\emph{non-blocking} manner, in which computation state is liberally suspended,
transferred and resumed from one machine to another.

This article is intended as a first introduction to \mbrace{}, its programming model and semantics.
It offers a detailed overview of the client API, runtime architecture and tooling.
We assume a certain degree of familiarity with the \fsharp{} language and parts
of its core library, although readers accustomed to languages with \texttt{ML}-like syntax
should be able to follow through.
Section \ref{sec:workflows} gives a detailed overview of the \mbrace{} programming model,
covering cloud workflows, distribution primitives and combinators.
Section \ref{sec:client} describes the \mbrace{} client API and tooling options,
while section \ref{sec:runtime} discusses runtime-specific concepts.
Finally, we offer an overview of the \mbrace{} internals and discuss future
development directions of the project.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "mbrace"
%%% End: 
